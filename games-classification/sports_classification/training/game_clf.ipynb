{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEIrtLZ2FLNA"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir ~/.kaggle\n",
        "cp kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "kaggle datasets download gpiosenka/sports-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sports-classification"
      ],
      "metadata": {
        "id": "ZvgvcrqrEKQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf                                                         # load tensorflow\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "GBzIhRe3FjL0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=os.listdir('/content/archive/Mushrooms')                                                  # get all classes names\n",
        "print('Total classes:',len(classes))                                            # total classes\n",
        "print('Class names:',classes)                                                   # class names\n",
        "# clean class names\n",
        "classes_clean=[re.sub('[^A-Za-z0-9 ]',' ',class_) for class_ in classes]        # remove unwanted characters\n",
        "classes_clean=[re.sub('[ ]+','_',class_).casefold() for class_ in classes_clean]# replace one or multiple spaces by underscore '_'\n",
        "print('Cleaned Class names:',classes_clean)                                     # clean class names\n",
        "# rename class names with clean class names\n",
        "for old_name,new_name in zip(classes,classes_clean):                            # get old and new class names\n",
        "  os.rename(os.path.join('/content/archive/Mushrooms',old_name),os.path.join('/content/archive/Mushrooms',new_name))# rename with new class names\n",
        "# get minimum class count ------------------------------------------------------\n",
        "class_counts:dict=dict()                                                        # get class samples for each class\n",
        "# get number of files in each class\n",
        "for class_ in os.listdir('/content/archive/Mushrooms'):                                           # get class name folder\n",
        "  class_counts[class_]=len(os.listdir(os.path.join('/content/archive/Mushrooms',class_)))         # count samples in given class\n",
        "print('Class counts:',class_counts)                                             # print class counts\n",
        "minimum_class_count=min(class_counts.values())                                  # get minimum class count\n",
        "test_split_size:int=int(minimum_class_count*10/100)                             # get test split size\n",
        "# make train and test directory\n",
        "os.mkdir('test')                                                                # make directory to store test data\n",
        "# move 10% of minimum class count from each directory\n",
        "for class_ in os.listdir('/content/archive/Mushrooms'):\n",
        "  os.mkdir(os.path.join('test',class_))                                         # make folder in test directory\n",
        "  # make move randomly selected images from main to test directory\n",
        "  for image in np.random.choice(os.listdir(os.path.join('/content/archive/Mushrooms',class_)),replace=False,size=test_split_size):# get image by image\n",
        "    os.rename(os.path.join('/content/archive/Mushrooms',class_,image),os.path.join('test',class_,image))# make move image\n",
        "os.rename('/content/archive/Mushrooms','train')"
      ],
      "metadata": {
        "id": "iD2KhRDGGPp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "imFK54rwxhb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset - train, test and valid\n",
        "train=tf.keras.utils.image_dataset_from_directory('train',labels='inferred',label_mode='int',class_names=None,color_mode='rgb',\n",
        "                                                  batch_size=128,image_size=(256,256),shuffle=True,validation_split=0.3,\n",
        "                                                  interpolation='bilinear',subset='training',seed=8,)\n",
        "valid=tf.keras.utils.image_dataset_from_directory('train',labels='inferred',label_mode='int',class_names=None,color_mode='rgb',\n",
        "                                                  batch_size=128,image_size=(256,256),shuffle=True,validation_split=0.3,\n",
        "                                                  interpolation='bilinear',subset='validation',seed=8,)\n",
        "test=tf.keras.utils.image_dataset_from_directory('test',labels='inferred',label_mode='int',class_names=None,color_mode='rgb',\n",
        "                                                 batch_size=128,image_size=(256,256),shuffle=False,validation_split=0.0,\n",
        "                                                 interpolation='bilinear',subset=None,seed=8,)\n",
        "print('Total training images:',train.cardinality()*32)\n",
        "print('Total validation images:',valid.cardinality()*32)\n",
        "print('Total test images:',test.cardinality()*32)\n",
        "training_classes:list=train.class_names\n",
        "valid_classses:list=valid.class_names\n",
        "test_classes:list=test.class_names\n",
        "assert training_classes==valid_classses==test_classes,'class count in train, valid and test set is not same'\n",
        "print('Class names:',training_classes)"
      ],
      "metadata": {
        "id": "Cing19EkHBYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot data training data\n",
        "for images,labels in train.take(1):break                                        # get a batch of data\n",
        "images_to_plot:int=6                                                            # number of images to plot\n",
        "plt.figure(figsize=(15,15))                                                     # figure size\n",
        "for index in range(images_to_plot):                                             # loop over image index\n",
        "  plt.subplot(3,3,index+1)                                                      # subplot rows = 3, columns = 3\n",
        "  plt.imshow(images[index].numpy().astype('uint8'))                             # make plot image\n",
        "  plt.axis('off')                                                               # make axis off\n",
        "  plt.title(training_classes[labels[index].numpy()])                            # make add labels as class names\n",
        "plt.tight_layout()                                                              # adjust layout space\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lT2okxErHNPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Maximum pixel values:',tf.reduce_max(images))                            # maximum pixel values in inputs\n",
        "print('Minimum pixel values:',tf.reduce_min(images))                            # minimum pixel values in inputs\n",
        "print('Object type of inputs (X):',type(images))                                # input types\n",
        "print('Data type in inputs (X):',images.dtype)                                  # data type in inputs\n",
        "print('Object type of outputs (y):',type(labels))                               # output types\n",
        "print('Data type in outputs (X):',labels.dtype)"
      ],
      "metadata": {
        "id": "C9guBcAXHSan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make apply data augmentation to data (add more randomness to data)\n",
        "# source: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "random_flip=tf.keras.layers.RandomFlip('horizontal_and_vertical',name='random_flip')# random flip layer\n",
        "random_zoom=tf.keras.layers.RandomZoom(height_factor=0.1,width_factor=0.1,name='random_zoom')# random zoom layer\n",
        "random_rotate=tf.keras.layers.RandomRotation(0.3,name='random_rotate')          # random rotate layers\n",
        "random_brightness=tf.keras.layers.RandomBrightness(0.3,value_range=(0.0,255.0),name='random_brightness')# random brightness layer\n",
        "augmentations=[random_flip,random_zoom,random_rotate,random_brightness]         # make list of data augmentation\n",
        "# make apply augmentation on training data\n",
        "for augmentation in augmentations:\n",
        "  train.map(lambda images,labels: (augmentation(images),labels))"
      ],
      "metadata": {
        "id": "2DkTtnzOHaFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9NOZpAUHhsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential(layers=None,name='Mushroom_classifier')\n",
        "model.add(tf.keras.layers.Rescaling(1./255.,offset=0,name='rescaling_01',input_shape=(256,256,3)))\n",
        "# first forward pass :: inputs : (256,256,3) -> outputs : (64,64,32)\n",
        "model.add(tf.keras.layers.Conv2D(32,(7,7),strides=(2,2),padding='same',name='conv_32x7s2_02'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_03'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_04'))\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),strides=(2,2),padding='same',name='conv_32x3s2_05'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_06'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_07'))\n",
        "# second forward pass :: inputs : (64,64,32) -> outputs : (32,32,64)\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),strides=(1,1),padding='same',name='conv_64x3s1_08'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_09'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_10'))\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),strides=(2,2),padding='same',name='conv_64x3s2_11'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_12'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_13'))\n",
        "# third forward pass :: inputs : (32,32,64) -> outputs : (16,16,128)\n",
        "model.add(tf.keras.layers.Conv2D(128,(3,3),strides=(1,1),padding='same',name='conv_128x3s1_12'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_13'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_14'))\n",
        "model.add(tf.keras.layers.Conv2D(128,(3,3),strides=(2,2),padding='same',name='conv_128x3s2_15'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_16'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_17'))\n",
        "# fourth forward pass :: inputs : (16,16,128) -> outputs : (8,8,256)\n",
        "model.add(tf.keras.layers.Conv2D(256,(3,3),strides=(1,1),padding='same',name='conv_256x3s1_18'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_19'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_20'))\n",
        "model.add(tf.keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same',name='conv_256x3s2_21'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_22'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_23'))\n",
        "# add dense map to network\n",
        "model.add(tf.keras.layers.Flatten(name='flatten_24'))\n",
        "model.add(tf.keras.layers.Dense(1024,activation='relu',name='dense_1024_25'))\n",
        "model.add(tf.keras.layers.Dropout(0.3,name='dropout_0__3_26'))\n",
        "model.add(tf.keras.layers.Dense(1024,activation='relu',name='dense_1024_27'))\n",
        "model.add(tf.keras.layers.Dropout(0.3,name='dropout_0__3_28'))\n",
        "model.add(tf.keras.layers.Dense(len(training_classes),activation='softmax',name=f'dense_{len(training_classes)}_output_29'))\n",
        "\n",
        "\n",
        "# make print model summary\n",
        "model.summary(line_length=120,expand_nested=True,show_trainable=True)"
      ],
      "metadata": {
        "id": "5rrGZWPCh7iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
      ],
      "metadata": {
        "id": "HkdA2T-aH1Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make early stopping\n",
        "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',min_delta=0,patience=10,verbose=1,mode='auto',restore_best_weights=True)\n",
        "\n",
        "# make train model\n",
        "history=model.fit(train,batch_size=128,epochs=10_000,verbose=2,callbacks=[early_stop],validation_split=0,validation_data=valid,\n",
        "                  shuffle=True)"
      ],
      "metadata": {
        "id": "uLx3jTdZIAC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot training accuracy and validation accuracy\n",
        "pd.DataFrame(history.history)[['sparse_categorical_accuracy','val_sparse_categorical_accuracy']].plot(marker='.')# make plot\n",
        "plt.grid(),plt.title('Training Accuracy'),plt.xlabel('epochs'),plt.ylabel('accuracy')# add grid, title and axis labels\n",
        "plt.show()                                                                      # make plot show"
      ],
      "metadata": {
        "id": "u3lfwfLsIMOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot training losses and validation losses\n",
        "pd.DataFrame(history.history)[['loss','val_loss']].plot(marker='.')             # make plot\n",
        "plt.grid(),plt.title('Training Losses'),plt.xlabel('epochs'),plt.ylabel('loss') # add grid, title and axis labels\n",
        "plt.show()                                                                      # make plot show"
      ],
      "metadata": {
        "id": "I9BgLdPRUtmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "results=model.evaluate(test,batch_size=None,verbose=\"auto\",sample_weight=None,return_dict=True)\n",
        "print('Testing results:',results)                                               # make print results"
      ],
      "metadata": {
        "id": "CH5uNhGvUzb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make save model (weights and configuration)\n",
        "model.save('game_clf',overwrite=True,save_format=None)               # make save"
      ],
      "metadata": {
        "id": "-yKXu9ybU0Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r -qq \"game_clf.zip\" \"game_clf\"                     # make zip model\n",
        "# make auto download model weights\n",
        "from google.colab import files                                                  # load file class\n",
        "files.download('game_clf.zip')                                       # download model zip file"
      ],
      "metadata": {
        "id": "Zhkf9jLwVMqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}