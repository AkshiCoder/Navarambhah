{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZkEx0kOTn5D"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir ~/.kaggle\n",
        "cp kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "kaggle datasets download  gpiosenka/cards-image-datasetclassification\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/cards-image-datasetclassification.zip"
      ],
      "metadata": {
        "id": "CDO9y1mnDBs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf                                                         # load tensorflow\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "gcuXUEP_TunU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset - train, test and valid\n",
        "train=tf.keras.utils.image_dataset_from_directory('train',labels='inferred',label_mode='int',class_names=None,color_mode='rgb',\n",
        "                                                  batch_size=128,image_size=(256,256),shuffle=True,validation_split=0.3,\n",
        "                                                  interpolation='bilinear',subset='training',seed=8,)\n",
        "valid=tf.keras.utils.image_dataset_from_directory('train',labels='inferred',label_mode='int',class_names=None,color_mode='rgb',\n",
        "                                                  batch_size=128,image_size=(256,256),shuffle=True,validation_split=0.3,\n",
        "                                                  interpolation='bilinear',subset='validation',seed=8,)\n",
        "test=tf.keras.utils.image_dataset_from_directory('test',labels='inferred',label_mode='int',class_names=None,color_mode='rgb',\n",
        "                                                 batch_size=128,image_size=(256,256),shuffle=False,validation_split=0.0,\n",
        "                                                 interpolation='bilinear',subset=None,seed=8,)\n",
        "print('Total training images:',train.cardinality()*32)\n",
        "print('Total validation images:',valid.cardinality()*32)\n",
        "print('Total test images:',test.cardinality()*32)\n",
        "training_classes:list=train.class_names\n",
        "valid_classses:list=valid.class_names\n",
        "test_classes:list=test.class_names\n",
        "assert training_classes==valid_classses==test_classes,'class count in train, valid and test set is not same'\n",
        "print('Class names:',training_classes)"
      ],
      "metadata": {
        "id": "sn06OvUOUysG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot data training data\n",
        "for images,labels in train.take(1):break                                        # get a batch of data\n",
        "images_to_plot:int=6                                                            # number of images to plot\n",
        "plt.figure(figsize=(15,15))                                                     # figure size\n",
        "for index in range(images_to_plot):                                             # loop over image index\n",
        "  plt.subplot(3,3,index+1)                                                      # subplot rows = 3, columns = 3\n",
        "  plt.imshow(images[index].numpy().astype('uint8'))                             # make plot image\n",
        "  plt.axis('off')                                                               # make axis off\n",
        "  plt.title(training_classes[labels[index].numpy()])                            # make add labels as class names\n",
        "plt.tight_layout()                                                              # adjust layout space\n",
        "plt.show()                                                                      # make plot show"
      ],
      "metadata": {
        "id": "zq6RVgIbU1lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Maximum pixel values:',tf.reduce_max(images))                            # maximum pixel values in inputs\n",
        "print('Minimum pixel values:',tf.reduce_min(images))                            # minimum pixel values in inputs\n",
        "print('Object type of inputs (X):',type(images))                                # input types\n",
        "print('Data type in inputs (X):',images.dtype)                                  # data type in inputs\n",
        "print('Object type of outputs (y):',type(labels))                               # output types\n",
        "print('Data type in outputs (X):',labels.dtype)                                 # data type in outputs"
      ],
      "metadata": {
        "id": "-PjoswtxU4M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make apply data augmentation to data (add more randomness to data)\n",
        "# source: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "random_flip=tf.keras.layers.RandomFlip('horizontal_and_vertical',name='random_flip')# random flip layer\n",
        "random_zoom=tf.keras.layers.RandomZoom(height_factor=0.1,width_factor=0.1,name='random_zoom')# random zoom layer\n",
        "random_rotate=tf.keras.layers.RandomRotation(0.3,name='random_rotate')          # random rotate layers\n",
        "random_brightness=tf.keras.layers.RandomBrightness(0.3,value_range=(0.0,255.0),name='random_brightness')# random brightness layer\n",
        "augmentations=[random_flip,random_zoom,random_rotate,random_brightness]         # make list of data augmentation\n",
        "# make apply augmentation on training data\n",
        "for augmentation in augmentations:\n",
        "  train.map(lambda images,labels: (augmentation(images),labels))                # make apply augmentation"
      ],
      "metadata": {
        "id": "UdWirluuU62o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential(layers=None,name='resisc45_classifier')\n",
        "model.add(tf.keras.layers.Rescaling(1./255.,offset=0,name='rescaling_01',input_shape=(256,256,3)))\n",
        "# first forward pass :: inputs : (256,256,3) -> outputs : (64,64,32)\n",
        "model.add(tf.keras.layers.Conv2D(32,(7,7),strides=(2,2),padding='same',name='conv_32x7s2_02'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_03'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_04'))\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),strides=(2,2),padding='same',name='conv_32x3s2_05'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_06'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_07'))\n",
        "# second forward pass :: inputs : (64,64,32) -> outputs : (32,32,64)\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),strides=(1,1),padding='same',name='conv_64x3s1_08'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_09'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_10'))\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),strides=(2,2),padding='same',name='conv_64x3s2_11'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_12'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_13'))\n",
        "# third forward pass :: inputs : (32,32,64) -> outputs : (16,16,128)\n",
        "model.add(tf.keras.layers.Conv2D(128,(3,3),strides=(1,1),padding='same',name='conv_128x3s1_12'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_13'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_14'))\n",
        "model.add(tf.keras.layers.Conv2D(128,(3,3),strides=(2,2),padding='same',name='conv_128x3s2_15'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_16'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_17'))\n",
        "# fourth forward pass :: inputs : (16,16,128) -> outputs : (8,8,256)\n",
        "model.add(tf.keras.layers.Conv2D(256,(3,3),strides=(1,1),padding='same',name='conv_256x3s1_18'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_19'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_20'))\n",
        "model.add(tf.keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same',name='conv_256x3s2_21'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='btz_norm_22'))\n",
        "model.add(tf.keras.layers.ReLU(name='relu_23'))\n",
        "# add dense map to network\n",
        "model.add(tf.keras.layers.Flatten(name='flatten_24'))\n",
        "model.add(tf.keras.layers.Dense(1024,activation='relu',name='dense_1024_25'))\n",
        "model.add(tf.keras.layers.Dropout(0.3,name='dropout_0__3_26'))\n",
        "model.add(tf.keras.layers.Dense(1024,activation='relu',name='dense_1024_27'))\n",
        "model.add(tf.keras.layers.Dropout(0.3,name='dropout_0__3_28'))\n",
        "model.add(tf.keras.layers.Dense(len(training_classes),activation='softmax',name=f'dense_{len(training_classes)}_output_29'))\n",
        "\n",
        "\n",
        "# make print model summary\n",
        "model.summary(line_length=120,expand_nested=True,show_trainable=True)"
      ],
      "metadata": {
        "id": "g8u60vVNU9YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
      ],
      "metadata": {
        "id": "RgEHLxyAVACC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make early stopping\n",
        "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=10,verbose=1,mode='auto',restore_best_weights=True)\n",
        "\n",
        "# make train model\n",
        "history=model.fit(train,batch_size=128,epochs=10_000,verbose=2,callbacks=[early_stop],validation_split=0,validation_data=valid,\n",
        "                  shuffle=True)"
      ],
      "metadata": {
        "id": "fOXoeoMcVEa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see model history (first five epoches)\n",
        "pd.DataFrame(history.history).head()"
      ],
      "metadata": {
        "id": "yg1o8YI1oYUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see model history (last five epoches)\n",
        "pd.DataFrame(history.history).tail()"
      ],
      "metadata": {
        "id": "dj7R6iyxofCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot training accuracy and validation accuracy\n",
        "pd.DataFrame(history.history)[['sparse_categorical_accuracy','val_sparse_categorical_accuracy']].plot(marker='.')# make plot\n",
        "plt.grid(),plt.title('Training Accuracy'),plt.xlabel('epochs'),plt.ylabel('accuracy')# add grid, title and axis labels\n",
        "plt.show()                                                                      # make plot show"
      ],
      "metadata": {
        "id": "oC1dCckMolsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot training losses and validation losses\n",
        "pd.DataFrame(history.history)[['loss','val_loss']].plot(marker='.')             # make plot\n",
        "plt.grid(),plt.title('Training Losses'),plt.xlabel('epochs'),plt.ylabel('loss') # add grid, title and axis labels\n",
        "plt.show()                                                                      # make plot show"
      ],
      "metadata": {
        "id": "UMnG1naforNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "results=model.evaluate(test,batch_size=None,verbose=\"auto\",sample_weight=None,return_dict=True)\n",
        "print('Testing results:',results)                                               # make print results"
      ],
      "metadata": {
        "id": "1QY0LqNKorcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make save model (weights and configuration)\n",
        "model.save('Xception_play_cards',overwrite=True,save_format=None)               # make save"
      ],
      "metadata": {
        "id": "HqWYMC_3o2Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r -qq \"Xception_play_cards.zip\" \"rps\"                     # make zip model\n",
        "# make auto download model weights\n",
        "from google.colab import files                                                  # load file class\n",
        "files.download('Xception_play_cards.zip')                                       # download model zip file"
      ],
      "metadata": {
        "id": "n7ir3dR1o7eq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}